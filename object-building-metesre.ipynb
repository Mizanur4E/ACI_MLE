{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-06-01T10:57:27.401864Z","iopub.execute_input":"2023-06-01T10:57:27.402216Z","iopub.status.idle":"2023-06-01T10:57:27.434491Z","shell.execute_reply.started":"2023-06-01T10:57:27.402185Z","shell.execute_reply":"2023-06-01T10:57:27.433555Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/training-uk-nopadding/part_0_validation.parquet\n/kaggle/input/training-uk-nopadding/df_valid_nayan5.csv\n/kaggle/input/training-uk-nopadding/processed_nvt/part_0_filtered_10.parquet\n/kaggle/input/training-uk-nopadding/processed_nvt/_metadata.json\n/kaggle/input/training-uk-nopadding/processed_nvt/test_0.parquet\n/kaggle/input/training-uk-nopadding/processed_nvt/part_0.parquet\n/kaggle/input/training-uk-nopadding/processed_nvt/schema.pbtxt\n/kaggle/input/training-uk-nopadding/processed_nvt/_metadata\n/kaggle/input/training-uk-nopadding/processed_nvt/part_0_filtered_20.parquet\n/kaggle/input/training-uk-nopadding/processed_nvt/.merlin/schema.json\n/kaggle/input/training-uk-nopadding/categories/unique.model.parquet\n/kaggle/input/training-uk-nopadding/categories/unique.title.parquet\n/kaggle/input/training-uk-nopadding/categories/cat_stats.brand.parquet\n/kaggle/input/training-uk-nopadding/categories/unique.session_id.parquet\n/kaggle/input/training-uk-nopadding/categories/unique.color.parquet\n/kaggle/input/training-uk-nopadding/categories/unique.desc.parquet\n/kaggle/input/training-uk-nopadding/categories/unique.material.parquet\n/kaggle/input/training-uk-nopadding/categories/unique.brand.parquet\n/kaggle/input/training-uk-nopadding/categories/unique.size.parquet\n/kaggle/input/training-uk-nopadding/categories/unique.prev_items.parquet\n/kaggle/input/training-uk-nopadding/categories/unique.author.parquet\n/kaggle/input/training-uk-nopadding/categories/unique.price.parquet\n","output_type":"stream"}]},{"cell_type":"code","source":"import cudf\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nimport numpy as np\n\n#corresponding to model\nimport tensorflow as tf\nfrom tensorflow.keras.layers import Embedding, GRU, Dense, Concatenate\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.callbacks import ModelCheckpoint\nfrom tensorflow.keras.utils import plot_model","metadata":{"execution":{"iopub.status.busy":"2023-06-01T10:57:28.277353Z","iopub.execute_input":"2023-06-01T10:57:28.277722Z","iopub.status.idle":"2023-06-01T10:57:39.618804Z","shell.execute_reply.started":"2023-06-01T10:57:28.277692Z","shell.execute_reply":"2023-06-01T10:57:39.617833Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"}]},{"cell_type":"code","source":" class Metesre():\n        \n        def __init__(self):\n            \n            \n            item_ids = cudf.read_parquet('/kaggle/input/training-uk-nopadding/categories/unique.prev_items.parquet')\n            self.items = item_ids['prev_items'] \n            self.INPUT_DATA_DIR = os.environ.get(\"INPUT_DATA_DIR\", \"/kaggle/input/training-uk-nopadding\")\n            self.sessions_gdf = pd.read_parquet(os.path.join(self.INPUT_DATA_DIR, \"processed_nvt/part_0_filtered.parquet\"))\n            self.test_gdf = pd.read_parquet(os.path.join(self.INPUT_DATA_DIR, \"processed_nvt/test_0.parquet\"))\n            self.preprocessing()\n            self.buildModel()\n            \n            \n            \n        def preprocessing(self):\n            \n            \n            X1 = self.sessions_gdf['prev_items-list'].tolist()\n            X2 = self.sessions_gdf['title-list'].tolist()\n            X3 = self.sessions_gdf['brand-list'].tolist()\n            X4 = self.sessions_gdf['size-list'].tolist()\n            X5 = self.sessions_gdf['model-list'].tolist()\n            X6 = self.sessions_gdf['color-list'].tolist()\n            \n            #handles variable length session sequences\n            X1 = np.array(X1, dtype='object')\n\n            #find vocab sizes\n            self.vocab_size1 = max(item for sublist in X1 for item in sublist)+1\n            self.vocab_size2 = max(item for sublist in X2 for item in sublist)+1\n            self.vocab_size3 = max(item for sublist in X3 for item in sublist)+1\n            self.vocab_size4 = max(item for sublist in X4 for item in sublist)+1\n            self.vocab_size5 = max(item for sublist in X5 for item in sublist)+1\n            self.vocab_size6 = max(item for sublist in X6 for item in sublist)+1\n            \n            print(\"Vocab Sizes: \\n\",self.vocab_size1, self.vocab_size2, self.vocab_size3, self.vocab_size4, self.vocab_size5, self.vocab_size6)\n            \n            #extract next item from the X1: prev_items_list, also remove last items attributes\n            X1_p = []\n            X2_p = []\n            X3_p = []\n            X4_p = []\n            X5_p = []\n            X6_p = []\n\n            y_p = []\n\n            for i in range(len(X1)):\n                X1_p.append(X1[i][:-1])\n                X2_p.append(X2[i][:-1])\n                X3_p.append(X3[i][:-1])\n                X4_p.append(X4[i][:-1])\n                X5_p.append(X5[i][:-1])\n                X6_p.append(X6[i][:-1])\n                y_p.append(X1[i][-1])\n                \n        \n            X1 = X1_p\n            X2 = X2_p\n            X3 = X3_p\n            X4 = X4_p\n            X5 = X5_p\n            X6 = X6_p\n            y= y_p\n            y = np.array(y)\n            \n            #padding: pre for X1 and post for all others\n            X1 = pad_sequences(X1, maxlen=200, padding='pre')\n            X2 = pad_sequences(X2, maxlen=200, padding='pre')\n            X3 = pad_sequences(X3, maxlen=200, padding='pre')\n            X4 = pad_sequences(X4, maxlen=200, padding='pre')\n            X5 = pad_sequences(X5, maxlen=200, padding='pre')\n            X6 = pad_sequences(X6, maxlen=200, padding='pre')\n\n            self.X1_train, self.X1_test, self.X2_train, self.X2_test, self.X3_train, self.X3_test, self.X4_train, \\\n            self.X4_test, self.X5_train, self.X5_test, self.X6_train, self.X6_test, self.y_train, self.y_test = train_test_split(X1, X2, X3, X4, \\\n                                                                                              X5, X6, y, test_size=0.005, random_state=42)\n        \n        def buildModel(self):\n            \n            embedding_dim = 128\n            hidden_units = 128\n            seq_length = 200\n\n            # Define the input layers\n            input_layer1 = tf.keras.Input(shape=(seq_length,))\n            input_layer2 = tf.keras.Input(shape=(seq_length,))\n            input_layer3 = tf.keras.Input(shape=(seq_length,))\n            input_layer4 = tf.keras.Input(shape=(seq_length,))\n            input_layer5 = tf.keras.Input(shape=(seq_length,))\n            input_layer6 = tf.keras.Input(shape=(seq_length,))\n\n            # Define the embedding layers\n            embedding_layer1 = Embedding(self.vocab_size1, embedding_dim)\n            embedding_layer2 = Embedding(self.vocab_size2, embedding_dim)\n            embedding_layer3 = Embedding(self.vocab_size3, embedding_dim)\n            embedding_layer4 = Embedding(self.vocab_size4, embedding_dim)\n            embedding_layer5 = Embedding(self.vocab_size5, embedding_dim)\n            embedding_layer6 = Embedding(self.vocab_size6, embedding_dim)\n            \n\n            # Define the GRU layer\n            gru_layer = GRU(hidden_units, return_sequences=False)\n\n            # Define the output layer\n            output_layer = Dense(self.vocab_size1, activation='softmax')\n\n\n            # Connect the layers\n            embedded_input1 = embedding_layer1(input_layer1)\n            embedded_input2 = embedding_layer2(input_layer2)\n            embedded_input3 = embedding_layer3(input_layer3)\n            embedded_input4 = embedding_layer4(input_layer4)\n            embedded_input5 = embedding_layer5(input_layer5)\n            embedded_input6 = embedding_layer6(input_layer6)\n\n\n            # Concatenate the outputs of the two GRU layers\n            concatenated_output = Concatenate()([embedded_input1, embedded_input2, embedded_input3, embedded_input4, embedded_input5, embedded_input6])\n\n            gru_output = gru_layer(concatenated_output)\n\n\n            output = output_layer(gru_output)\n\n\n            # Create the model\n            self.model = Model(inputs=[input_layer1, input_layer2, input_layer3, input_layer4, input_layer5, input_layer6], outputs=output)\n\n            # Compile the model\n            self.model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=[tf.keras.metrics.CosineSimilarity(axis=1)])\n\n            # Print the model summary\n            self.model.summary()\n            \n            \n        def _mean_reciprocal_rank(recommendations, ground_truth):\n            \"\"\"\n            Calculate the Mean Reciprocal Rank (MRR) of a recommendation system.\n\n            :param recommendations: A list of lists containing the recommended items for each query.\n            :param ground_truth: A list containing the ground truth (relevant) items for each query.\n            :return: The Mean Reciprocal Rank (MRR) value as a float.\n            \"\"\"\n            assert len(recommendations) == len(ground_truth), \"Recommendations and ground truth lists must have the same length.\"\n\n            reciprocal_ranks = []\n\n            for rec, gt in zip(recommendations, ground_truth):\n                for rank, item in enumerate(rec, start=1):\n                    if item == gt:\n                        reciprocal_ranks.append(1 / rank)\n                        break\n                else:\n                    reciprocal_ranks.append(0)\n\n            mrr = sum(reciprocal_ranks) / len(reciprocal_ranks)\n            return mrr\n\n\n        def train(self, epoch= 10, batch_size = 32):\n            \n            checkpoint_callback = ModelCheckpoint(\n                '/kaggle/working/model_checkpoint.h5',\n                monitor='val_loss',  \n                save_best_only=True,  \n                save_weights_only=False, \n                verbose=1 \n            )\n            \n            self.history = self.model.fit([ self.X1_train, self.X2_train, self.X3_train, self.X4_train, self.X5_train, self.X6_train], self.y_train, epochs = epoch, batch_size=batch_size, verbose = True, validation_split=0.1, callbacks=[checkpoint_callback])\n            \n        \n        \n        \n        def _decoder(self, recommendation):\n            \n            '''decode sequeces to ASIN ids'''\n            \n            decoded = []\n            for next_item in recommendation:\n\n                decoded.append([self.items.iloc[e] for e in next_item])\n\n            decoded = np.array(decoded)\n            return decoded\n            \n            \n            \n        def _predictor(self, X_test):\n            \n            '''generate y_pred (which is top 100 product indices) from the model for X_test. '''\n            \n            batch_size = 64\n            num_batches = int(np.ceil(len(X_test[0]) / batch_size))\n            print(len(X_test), num_batches)\n            y_pred = []\n            for batch_idx in range(num_batches+1):\n                \n                if batch_idx < num_batches:\n                    start_idx = batch_idx * batch_size\n                    end_idx = (batch_idx + 1) * batch_size\n                    \n                    inputs = []\n                \n                    for i in range(len(X_test)):\n                        inputs.append(X_test[i][start_idx:end_idx])\n                        \n                    predictions = self.model.predict(inputs)\n                    recom_size = 100\n                    recom = []\n\n                    for pred in predictions:\n\n                        indices = [i for i, _ in sorted(enumerate(pred), key=lambda x: x[1], reverse=True)[:recom_size]]\n                        recom.append(indices)\n\n                    y_pred = y_pred + recom\n                    \n                else:\n\n                    inputs = X_test[end_idx:]\n                    predictions = self.model.predict(inputs)\n                    recom_size = 100\n                    recom = []\n\n                    for pred in predictions:\n\n                        indices = [i for i, _ in sorted(enumerate(pred), key=lambda x: x[1], reverse=True)[:recom_size]]\n                        recom.append(indices)\n\n                    y_pred = y_pred + recom\n                    \n            return y_pred\n            \n            \n        def test_1_testontest(self):\n            \n            \n            '''evaluate model's performance on the test set defined in the initialization '''\n            #update it for all the test sessions instead of only 200\n            \n            recommendation = self._predictor(self, [self.X1_test, self.X2_test, self.X3_test, self.X4_test, self.X5_test, self.X6_test])\n            gnd = self.y_test.tolist()\n            self.test1_MRR = self._mean_reciprocal_rank(recommendation, gnd)\n            print(f'MRR for test1: {self.test1_MRR}')\n\n    \n        \n            \n        def test_2_testwithendone(self):\n            \n            ''' evaluate model's performance on the given test set. Since test set has no ground truth\n            we will split the last item in the session and consider it as the next item and evaulate model\n            performance'''\n            \n            pass\n        \n    \n        def test_3_generatefinalresult(self):\n            \n            \n            ''' generates predictions of test set. Decodes the index and return the recommendations with ASIN ids'''\n            \n            rec = _predictor(self, self.test_gdf)\n            y_pred = _decoder(self, rec)\n            df = pd.DataFrame()\n            df['next_item_prediction'] = y_pred\n            \n            return df\n            ","metadata":{"execution":{"iopub.status.busy":"2023-06-01T10:57:53.353614Z","iopub.execute_input":"2023-06-01T10:57:53.354034Z","iopub.status.idle":"2023-06-01T10:57:53.425573Z","shell.execute_reply.started":"2023-06-01T10:57:53.353999Z","shell.execute_reply":"2023-06-01T10:57:53.424453Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"ob = Metesre()\n# plot_model(ob.model)","metadata":{"execution":{"iopub.status.busy":"2023-06-01T10:57:55.817548Z","iopub.execute_input":"2023-06-01T10:57:55.818016Z","iopub.status.idle":"2023-06-01T10:57:57.566853Z","shell.execute_reply.started":"2023-06-01T10:57:55.817977Z","shell.execute_reply":"2023-06-01T10:57:57.563082Z"},"trusted":true},"execution_count":5,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m ob \u001b[38;5;241m=\u001b[39m \u001b[43mMetesre\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# plot_model(ob.model)\u001b[39;00m\n","Cell \u001b[0;32mIn[4], line 9\u001b[0m, in \u001b[0;36mMetesre.__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems \u001b[38;5;241m=\u001b[39m item_ids[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprev_items\u001b[39m\u001b[38;5;124m'\u001b[39m] \n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mINPUT_DATA_DIR \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mINPUT_DATA_DIR\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/kaggle/input/training-uk-nopadding\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msessions_gdf \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_parquet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mINPUT_DATA_DIR\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprocessed_nvt/part_0_filtered.parquet\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_gdf \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_parquet(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mINPUT_DATA_DIR, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprocessed_nvt/test_0.parquet\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocessing()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parquet.py:503\u001b[0m, in \u001b[0;36mread_parquet\u001b[0;34m(path, engine, columns, storage_options, use_nullable_dtypes, **kwargs)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    457\u001b[0m \u001b[38;5;124;03mLoad a parquet object from the file path, returning a DataFrame.\u001b[39;00m\n\u001b[1;32m    458\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    499\u001b[0m \u001b[38;5;124;03mDataFrame\u001b[39;00m\n\u001b[1;32m    500\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    501\u001b[0m impl \u001b[38;5;241m=\u001b[39m get_engine(engine)\n\u001b[0;32m--> 503\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimpl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    504\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    505\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    506\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    507\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_nullable_dtypes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_nullable_dtypes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    508\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    509\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parquet.py:244\u001b[0m, in \u001b[0;36mPyArrowImpl.read\u001b[0;34m(self, path, columns, use_nullable_dtypes, storage_options, **kwargs)\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m manager \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    242\u001b[0m     to_pandas_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplit_blocks\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[assignment]\u001b[39;00m\n\u001b[0;32m--> 244\u001b[0m path_or_handle, handles, kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfilesystem\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43m_get_path_or_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    245\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    246\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfilesystem\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    247\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    248\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    249\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    251\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi\u001b[38;5;241m.\u001b[39mparquet\u001b[38;5;241m.\u001b[39mread_table(\n\u001b[1;32m    252\u001b[0m         path_or_handle, columns\u001b[38;5;241m=\u001b[39mcolumns, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    253\u001b[0m     )\u001b[38;5;241m.\u001b[39mto_pandas(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mto_pandas_kwargs)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parquet.py:102\u001b[0m, in \u001b[0;36m_get_path_or_handle\u001b[0;34m(path, fs, storage_options, mode, is_dir)\u001b[0m\n\u001b[1;32m     92\u001b[0m handles \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;129;01mnot\u001b[39;00m fs\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_dir\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;66;03m# fsspec resources can also point to directories\u001b[39;00m\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;66;03m# this branch is used for example when reading from non-fsspec URLs\u001b[39;00m\n\u001b[0;32m--> 102\u001b[0m     handles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    103\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath_or_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\n\u001b[1;32m    104\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    105\u001b[0m     fs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    106\u001b[0m     path_or_handle \u001b[38;5;241m=\u001b[39m handles\u001b[38;5;241m.\u001b[39mhandle\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/common.py:865\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    856\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    857\u001b[0m             handle,\n\u001b[1;32m    858\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    861\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    862\u001b[0m         )\n\u001b[1;32m    863\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    864\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m--> 865\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    866\u001b[0m     handles\u001b[38;5;241m.\u001b[39mappend(handle)\n\u001b[1;32m    868\u001b[0m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/kaggle/input/training-uk-nopadding/processed_nvt/part_0_filtered.parquet'"],"ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '/kaggle/input/training-uk-nopadding/processed_nvt/part_0_filtered.parquet'","output_type":"error"}]},{"cell_type":"code","source":"/kaggle/input/training-uk-nopadding\n/kaggle/input/training-uk-nopadding/processed_nvt/part_0_filtered.parquet","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ob.train(epoch = 2)","metadata":{"execution":{"iopub.status.busy":"2023-06-01T10:04:47.221795Z","iopub.execute_input":"2023-06-01T10:04:47.222200Z","iopub.status.idle":"2023-06-01T10:10:19.517982Z","shell.execute_reply.started":"2023-06-01T10:04:47.222156Z","shell.execute_reply":"2023-06-01T10:10:19.516021Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"Epoch 1/2\n1517/1517 [==============================] - ETA: 0s - loss: 12.0649 - cosine_similarity: 364.1420\nEpoch 1: val_loss improved from inf to 11.13963, saving model to /kaggle/working/model_checkpoint.h5\n1517/1517 [==============================] - 216s 141ms/step - loss: 12.0649 - cosine_similarity: 364.1420 - val_loss: 11.1396 - val_cosine_similarity: 252.7435\nEpoch 2/2\n1517/1517 [==============================] - ETA: 0s - loss: 8.2553 - cosine_similarity: 59.9196\nEpoch 2: val_loss improved from 11.13963 to 11.08871, saving model to /kaggle/working/model_checkpoint.h5\n1517/1517 [==============================] - 115s 76ms/step - loss: 8.2553 - cosine_similarity: 59.9196 - val_loss: 11.0887 - val_cosine_similarity: 63.1359\n","output_type":"stream"}]},{"cell_type":"code","source":"ob._predictor([ob.X1_test, ob.X2_test, ob.X3_test, ob.X4_test, ob.X5_test, ob.X6_test])","metadata":{"execution":{"iopub.status.busy":"2023-06-01T10:21:02.180206Z","iopub.execute_input":"2023-06-01T10:21:02.180753Z","iopub.status.idle":"2023-06-01T10:50:42.742758Z","shell.execute_reply.started":"2023-06-01T10:21:02.180725Z","shell.execute_reply":"2023-06-01T10:50:42.740593Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"6 45\n2/2 [==============================] - 1s 11ms/step\n2/2 [==============================] - 0s 10ms/step\n2/2 [==============================] - 0s 9ms/step\n2/2 [==============================] - 0s 9ms/step\n2/2 [==============================] - 0s 9ms/step\n2/2 [==============================] - 0s 9ms/step\n2/2 [==============================] - 0s 9ms/step\n2/2 [==============================] - 0s 8ms/step\n2/2 [==============================] - 0s 9ms/step\n2/2 [==============================] - 0s 9ms/step\n2/2 [==============================] - 0s 9ms/step\n2/2 [==============================] - 0s 10ms/step\n2/2 [==============================] - 0s 9ms/step\n2/2 [==============================] - 0s 9ms/step\n2/2 [==============================] - 0s 9ms/step\n2/2 [==============================] - 0s 9ms/step\n2/2 [==============================] - 0s 9ms/step\n2/2 [==============================] - 0s 9ms/step\n2/2 [==============================] - 0s 9ms/step\n2/2 [==============================] - 0s 9ms/step\n2/2 [==============================] - 0s 9ms/step\n2/2 [==============================] - 0s 9ms/step\n2/2 [==============================] - 0s 13ms/step\n2/2 [==============================] - 0s 9ms/step\n2/2 [==============================] - 0s 11ms/step\n2/2 [==============================] - 0s 9ms/step\n2/2 [==============================] - 0s 9ms/step\n2/2 [==============================] - 0s 9ms/step\n2/2 [==============================] - 0s 9ms/step\n2/2 [==============================] - 0s 12ms/step\n2/2 [==============================] - 0s 9ms/step\n2/2 [==============================] - 0s 9ms/step\n2/2 [==============================] - 0s 9ms/step\n2/2 [==============================] - 0s 9ms/step\n2/2 [==============================] - 0s 8ms/step\n2/2 [==============================] - 0s 9ms/step\n2/2 [==============================] - 0s 9ms/step\n2/2 [==============================] - 0s 9ms/step\n","output_type":"stream"},{"name":"stderr","text":"Exception ignored in: <function _xla_gc_callback at 0x7899d5a62290>\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/site-packages/jax/_src/lib/__init__.py\", line 103, in _xla_gc_callback\n    def _xla_gc_callback(*args):\nKeyboardInterrupt: \n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[29], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mob\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predictor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mob\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mX1_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mob\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mX2_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mob\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mX3_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mob\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mX4_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mob\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mX5_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mob\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mX6_test\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[27], line 216\u001b[0m, in \u001b[0;36mMetesre._predictor\u001b[0;34m(self, X_test)\u001b[0m\n\u001b[1;32m    212\u001b[0m recom \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m pred \u001b[38;5;129;01min\u001b[39;00m predictions:\n\u001b[0;32m--> 216\u001b[0m     indices \u001b[38;5;241m=\u001b[39m [i \u001b[38;5;28;01mfor\u001b[39;00m i, _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(\u001b[38;5;28menumerate\u001b[39m(pred), key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[38;5;241m1\u001b[39m], reverse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)[:recom_size]]\n\u001b[1;32m    217\u001b[0m     recom\u001b[38;5;241m.\u001b[39mappend(indices)\n\u001b[1;32m    219\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m y_pred \u001b[38;5;241m+\u001b[39m recom\n","Cell \u001b[0;32mIn[27], line 216\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    212\u001b[0m recom \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m pred \u001b[38;5;129;01min\u001b[39;00m predictions:\n\u001b[0;32m--> 216\u001b[0m     indices \u001b[38;5;241m=\u001b[39m [i \u001b[38;5;28;01mfor\u001b[39;00m i, _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(\u001b[38;5;28menumerate\u001b[39m(pred), key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[38;5;241m1\u001b[39m], reverse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)[:recom_size]]\n\u001b[1;32m    217\u001b[0m     recom\u001b[38;5;241m.\u001b[39mappend(indices)\n\u001b[1;32m    219\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m y_pred \u001b[38;5;241m+\u001b[39m recom\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"ob.test_1_testontest()","metadata":{"execution":{"iopub.status.busy":"2023-06-01T10:50:42.782009Z","iopub.status.idle":"2023-06-01T10:50:42.782530Z","shell.execute_reply.started":"2023-06-01T10:50:42.782241Z","shell.execute_reply":"2023-06-01T10:50:42.782265Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}