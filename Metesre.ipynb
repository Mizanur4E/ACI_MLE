{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport cudf\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nimport numpy as np\n\n#corresponding to model\nimport tensorflow as tf\nfrom tensorflow.keras.layers import Embedding, GRU, Dense, Concatenate\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.callbacks import ModelCheckpoint\nfrom tensorflow.keras.utils import plot_model","metadata":{"execution":{"iopub.status.busy":"2023-06-01T13:19:00.086721Z","iopub.execute_input":"2023-06-01T13:19:00.087059Z","iopub.status.idle":"2023-06-01T13:19:12.930146Z","shell.execute_reply.started":"2023-06-01T13:19:00.087032Z","shell.execute_reply":"2023-06-01T13:19:12.929231Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"}]},{"cell_type":"code","source":" class Metesre():\n        \n        def __init__(self):\n            \n            \n            item_ids = cudf.read_parquet('/kaggle/input/training-uk-nopadding/categories/unique.prev_items.parquet')\n            self.items = item_ids['prev_items'] \n            self.INPUT_DATA_DIR = os.environ.get(\"INPUT_DATA_DIR\", \"/kaggle/input/training-uk-nopadding\")\n            self.sessions_gdf = pd.read_parquet(os.path.join(self.INPUT_DATA_DIR, \"processed_nvt/part_0_filtered_20.parquet\"))\n            self.test_gdf = pd.read_parquet(os.path.join(self.INPUT_DATA_DIR, \"processed_nvt/test_0.parquet\"))\n            self.preprocessing()\n            self.buildModel()\n            \n            \n            \n        def preprocessing(self):\n            \n            \n            X1 = self.sessions_gdf['prev_items-list'].tolist()\n            X2 = self.sessions_gdf['title-list'].tolist()\n            X3 = self.sessions_gdf['brand-list'].tolist()\n            X4 = self.sessions_gdf['size-list'].tolist()\n            X5 = self.sessions_gdf['model-list'].tolist()\n            X6 = self.sessions_gdf['color-list'].tolist()\n            \n            #handles variable length session sequences\n            X1 = np.array(X1, dtype='object')\n\n            #find vocab sizes\n            self.vocab_size1 = max(item for sublist in X1 for item in sublist)+1\n            self.vocab_size2 = max(item for sublist in X2 for item in sublist)+1\n            self.vocab_size3 = max(item for sublist in X3 for item in sublist)+1\n            self.vocab_size4 = max(item for sublist in X4 for item in sublist)+1\n            self.vocab_size5 = max(item for sublist in X5 for item in sublist)+1\n            self.vocab_size6 = max(item for sublist in X6 for item in sublist)+1\n            \n            print(\"Vocab Sizes: \\n\",self.vocab_size1, self.vocab_size2, self.vocab_size3, self.vocab_size4, self.vocab_size5, self.vocab_size6)\n            \n            #extract next item from the X1: prev_items_list, also remove last items attributes\n            X1_p = []\n            X2_p = []\n            X3_p = []\n            X4_p = []\n            X5_p = []\n            X6_p = []\n\n            y_p = []\n\n            for i in range(len(X1)):\n                X1_p.append(X1[i][:-1])\n                X2_p.append(X2[i][:-1])\n                X3_p.append(X3[i][:-1])\n                X4_p.append(X4[i][:-1])\n                X5_p.append(X5[i][:-1])\n                X6_p.append(X6[i][:-1])\n                y_p.append(X1[i][-1])\n                \n        \n            X1 = X1_p\n            X2 = X2_p\n            X3 = X3_p\n            X4 = X4_p\n            X5 = X5_p\n            X6 = X6_p\n            y= y_p\n            y = np.array(y)\n            \n            #padding: pre for X1 and post for all others\n            X1 = pad_sequences(X1, maxlen=200, padding='pre')\n            X2 = pad_sequences(X2, maxlen=200, padding='pre')\n            X3 = pad_sequences(X3, maxlen=200, padding='pre')\n            X4 = pad_sequences(X4, maxlen=200, padding='pre')\n            X5 = pad_sequences(X5, maxlen=200, padding='pre')\n            X6 = pad_sequences(X6, maxlen=200, padding='pre')\n\n            self.X1_train, self.X1_test, self.X2_train, self.X2_test, self.X3_train, self.X3_test, self.X4_train, \\\n            self.X4_test, self.X5_train, self.X5_test, self.X6_train, self.X6_test, self.y_train, self.y_test = train_test_split(X1, X2, X3, X4, \\\n                                                                                              X5, X6, y, test_size=0.05,random_state=42)\n        \n        def buildModel(self):\n            \n            embedding_dim = 128\n            hidden_units = 128\n            seq_length = 200\n\n            # Define the input layers\n            input_layer1 = tf.keras.Input(shape=(seq_length,))\n            input_layer2 = tf.keras.Input(shape=(seq_length,))\n            input_layer3 = tf.keras.Input(shape=(seq_length,))\n            input_layer4 = tf.keras.Input(shape=(seq_length,))\n            input_layer5 = tf.keras.Input(shape=(seq_length,))\n            input_layer6 = tf.keras.Input(shape=(seq_length,))\n\n            # Define the embedding layers\n            embedding_layer1 = Embedding(self.vocab_size1, embedding_dim)\n            embedding_layer2 = Embedding(self.vocab_size2, embedding_dim)\n            embedding_layer3 = Embedding(self.vocab_size3, embedding_dim)\n            embedding_layer4 = Embedding(self.vocab_size4, embedding_dim)\n            embedding_layer5 = Embedding(self.vocab_size5, embedding_dim)\n            embedding_layer6 = Embedding(self.vocab_size6, embedding_dim)\n            \n\n            # Define the GRU layer\n            gru_layer = GRU(hidden_units, return_sequences=False)\n\n            # Define the output layer\n            output_layer = Dense(self.vocab_size1, activation='softmax')\n\n\n            # Connect the layers\n            embedded_input1 = embedding_layer1(input_layer1)\n            embedded_input2 = embedding_layer2(input_layer2)\n            embedded_input3 = embedding_layer3(input_layer3)\n            embedded_input4 = embedding_layer4(input_layer4)\n            embedded_input5 = embedding_layer5(input_layer5)\n            embedded_input6 = embedding_layer6(input_layer6)\n\n\n            # Concatenate the outputs of the two GRU layers\n            concatenated_output = Concatenate()([embedded_input1, embedded_input2, embedded_input3, embedded_input4, embedded_input5, embedded_input6])\n\n            gru_output = gru_layer(concatenated_output)\n\n\n            output = output_layer(gru_output)\n\n\n            # Create the model\n            self.model = Model(inputs=[input_layer1, input_layer2, input_layer3, input_layer4, input_layer5, input_layer6], outputs=output)\n\n            # Compile the model\n            self.model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=[tf.keras.metrics.CosineSimilarity(axis=1)])\n\n            # Print the model summary\n            self.model.summary()\n            \n            \n        def _mean_reciprocal_rank(self, recommendations, ground_truth):\n            \"\"\"\n            Calculate the Mean Reciprocal Rank (MRR) of a recommendation system.\n\n            :param recommendations: A list of lists containing the recommended items for each query.\n            :param ground_truth: A list containing the ground truth (relevant) items for each query.\n            :return: The Mean Reciprocal Rank (MRR) value as a float.\n            \"\"\"\n            assert len(recommendations) == len(ground_truth), \"Recommendations and ground truth lists must have the same length.\"\n\n            reciprocal_ranks = []\n\n            for rec, gt in zip(recommendations, ground_truth):\n                for rank, item in enumerate(rec, start=1):\n                    if item == gt:\n                        reciprocal_ranks.append(1 / rank)\n                        break\n                else:\n                    reciprocal_ranks.append(0)\n\n            mrr = sum(reciprocal_ranks) / len(reciprocal_ranks)\n            return mrr\n\n\n        def train(self, epoch= 10, batch_size = 32):\n            \n            checkpoint_callback = ModelCheckpoint(\n                '/kaggle/working/model_checkpoint.h5',\n                monitor='val_loss',  \n                save_best_only=True,  \n                save_weights_only=False, \n                verbose=1 \n            )\n            \n            self.history = self.model.fit([ self.X1_train, self.X2_train, self.X3_train, self.X4_train, self.X5_train, self.X6_train], self.y_train, epochs = epoch, batch_size=batch_size, verbose = True, validation_split=0.1, callbacks=[checkpoint_callback])\n            \n        \n        \n        \n        def _decoder(self, recommendation):\n            \n            '''decode sequeces to ASIN ids'''\n            \n            decoded = []\n            for next_item in recommendation:\n\n                decoded.append([self.items.iloc[e] for e in next_item])\n\n            decoded = np.array(decoded)\n            return decoded\n            \n            \n            \n        def _predictor(self, X_test):\n            \n            '''generate y_pred (which is top 100 product indices) from the model for X_test. '''\n            \n            batch_size = 64\n            num_batches = int(len(X_test[0]) / batch_size)\n\n            y_pred = []\n            for batch_idx in range(num_batches+1):\n                \n                if batch_idx < num_batches:\n                    start_idx = batch_idx * batch_size\n                    end_idx = (batch_idx + 1) * batch_size\n                    \n                    inputs = []\n                \n                    for i in range(len(X_test)):\n                        inputs.append(X_test[i][start_idx:end_idx])\n                        \n                    predictions = self.model.predict(inputs)\n                    recom_size = 100\n            \n            \n                    top_preds = np.argpartition(predictions, -recom_size, axis=1)[:, -recom_size:]\n                    sorted_indices = np.argsort(predictions[np.arange(len(predictions))[:, None], top_preds], axis=1)[:, ::-1]\n                    recom = top_preds[np.arange(len(predictions))[:, None], sorted_indices]\n\n                    y_pred.append(recom)\n\n                        \n                else:\n                    \n                    inputs = []\n                \n                    for i in range(len(X_test)):\n                        \n                        inputs.append(X_test[i][end_idx:])\n                    \n                    predictions = self.model.predict(inputs)\n            \n                    top_preds = np.argpartition(predictions, -recom_size, axis=1)[:, -recom_size:]\n                    sorted_indices = np.argsort(predictions[np.arange(len(predictions))[:, None], top_preds], axis=1)[:, ::-1]\n                    recom = top_preds[np.arange(len(predictions))[:, None], sorted_indices]\n\n                    y_pred.append(recom)\n                \n            y_pred = [inner_list for outer_list in y_pred for inner_list in outer_list]\n                    \n            return y_pred\n            \n            \n        def test_1_testontest(self):\n            \n            \n            '''evaluate model's performance on the test set defined in the initialization '''\n            #update it for all the test sessions instead of only 200\n            \n            recommendation = self._predictor([self.X1_test, self.X2_test, self.X3_test, self.X4_test, self.X5_test, self.X6_test])\n            gnd = self.y_test.tolist()\n            self.test1_MRR = self._mean_reciprocal_rank(recommendation, gnd)\n            print(f'MRR for test1: {self.test1_MRR}')\n\n    \n        \n            \n        def test_2_testwithendone(self, n=100):\n            \n            ''' evaluate model's performance on the given test set. Since test set has no ground truth\n            we will split the last item in the session and consider it as the next item and evaulate model\n            performance'''\n            \n            \n            X1 = self.test_gdf['prev_items-list'].tolist()\n            X2 = self.test_gdf['title-list'].tolist()\n            X3 = self.test_gdf['brand-list'].tolist()\n            X4 = self.test_gdf['size-list'].tolist()\n            X5 = self.test_gdf['model-list'].tolist()\n            X6 = self.test_gdf['color-list'].tolist()\n            \n            #handles variable length session sequences\n            X1 = np.array(X1, dtype='object')\n\n\n            #extract next item from the X1: prev_items_list, also remove last items attributes\n            X1_p = []\n            X2_p = []\n            X3_p = []\n            X4_p = []\n            X5_p = []\n            X6_p = []\n\n            y_p = []\n\n            for i in range(len(X1)):\n                X1_p.append(X1[i][:-1])\n                X2_p.append(X2[i][:-1])\n                X3_p.append(X3[i][:-1])\n                X4_p.append(X4[i][:-1])\n                X5_p.append(X5[i][:-1])\n                X6_p.append(X6[i][:-1])\n                y_p.append(X1[i][-1])\n                \n        \n            X1 = X1_p\n            X2 = X2_p\n            X3 = X3_p\n            X4 = X4_p\n            X5 = X5_p\n            X6 = X6_p\n            y= y_p\n            y = np.array(y)\n            \n            #padding: pre for X1 and post for all others\n            X1 = pad_sequences(X1, maxlen=200, padding='pre')\n            X2 = pad_sequences(X2, maxlen=200, padding='pre')\n            X3 = pad_sequences(X3, maxlen=200, padding='pre')\n            X4 = pad_sequences(X4, maxlen=200, padding='pre')\n            X5 = pad_sequences(X5, maxlen=200, padding='pre')\n            X6 = pad_sequences(X6, maxlen=200, padding='pre')\n            \n           \n            rec = self._predictor([X1[:n], X2[:n], X3[:n], X4[:n], X5[:n], X6[:n]])\n            gnd = y[:n].tolist()\n            self.test2_MRR =  self._mean_reciprocal_rank(rec, gnd)\n            print(f'MRR for test1: {self.test2_MRR}')\n\n            \n        \n    \n        def test_3_generatefinalresult(self, n=100):\n            \n            \n            ''' generates predictions of test set. Decodes the index and return the recommendations with ASIN ids'''\n            \n            X1 = self.test_gdf['prev_items-list'].tolist()\n            X2 = self.test_gdf['title-list'].tolist()\n            X3 = self.test_gdf['brand-list'].tolist()\n            X4 = self.test_gdf['size-list'].tolist()\n            X5 = self.test_gdf['model-list'].tolist()\n            X6 = self.test_gdf['color-list'].tolist()\n \n\n            \n            X1 = pad_sequences(X1, maxlen=200, padding='pre')\n            X2 = pad_sequences(X2, maxlen=200, padding='pre')\n            X3 = pad_sequences(X3, maxlen=200, padding='pre')\n            X4 = pad_sequences(X4, maxlen=200, padding='pre')\n            X5 = pad_sequences(X5, maxlen=200, padding='pre')\n            X6 = pad_sequences(X6, maxlen=200, padding='pre')\n            \n          \n            rec = self._predictor([X1[:n], X2[:n], X3[:n], X4[:n], X5[:n], X6[:n]])\n\n            y_pred = self._decoder(rec)\n            y_pred = y_pred.tolist()\n            df = pd.DataFrame()\n            df['next_item_prediction'] = y_pred\n            \n            return df\n            ","metadata":{"execution":{"iopub.status.busy":"2023-06-01T13:20:02.684559Z","iopub.execute_input":"2023-06-01T13:20:02.684961Z","iopub.status.idle":"2023-06-01T13:20:02.746569Z","shell.execute_reply.started":"2023-06-01T13:20:02.684927Z","shell.execute_reply":"2023-06-01T13:20:02.745465Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"ob = Metesre()\n# plot_model(ob.model)","metadata":{"execution":{"iopub.status.busy":"2023-06-01T13:20:04.281500Z","iopub.execute_input":"2023-06-01T13:20:04.282179Z","iopub.status.idle":"2023-06-01T13:20:16.544887Z","shell.execute_reply.started":"2023-06-01T13:20:04.282140Z","shell.execute_reply":"2023-06-01T13:20:16.544137Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Vocab Sizes: \n 499121 581870 78971 88548 201795 89095\nModel: \"model\"\n__________________________________________________________________________________________________\n Layer (type)                   Output Shape         Param #     Connected to                     \n==================================================================================================\n input_1 (InputLayer)           [(None, 200)]        0           []                               \n                                                                                                  \n input_2 (InputLayer)           [(None, 200)]        0           []                               \n                                                                                                  \n input_3 (InputLayer)           [(None, 200)]        0           []                               \n                                                                                                  \n input_4 (InputLayer)           [(None, 200)]        0           []                               \n                                                                                                  \n input_5 (InputLayer)           [(None, 200)]        0           []                               \n                                                                                                  \n input_6 (InputLayer)           [(None, 200)]        0           []                               \n                                                                                                  \n embedding (Embedding)          (None, 200, 128)     63887488    ['input_1[0][0]']                \n                                                                                                  \n embedding_1 (Embedding)        (None, 200, 128)     74479360    ['input_2[0][0]']                \n                                                                                                  \n embedding_2 (Embedding)        (None, 200, 128)     10108288    ['input_3[0][0]']                \n                                                                                                  \n embedding_3 (Embedding)        (None, 200, 128)     11334144    ['input_4[0][0]']                \n                                                                                                  \n embedding_4 (Embedding)        (None, 200, 128)     25829760    ['input_5[0][0]']                \n                                                                                                  \n embedding_5 (Embedding)        (None, 200, 128)     11404160    ['input_6[0][0]']                \n                                                                                                  \n concatenate (Concatenate)      (None, 200, 768)     0           ['embedding[0][0]',              \n                                                                  'embedding_1[0][0]',            \n                                                                  'embedding_2[0][0]',            \n                                                                  'embedding_3[0][0]',            \n                                                                  'embedding_4[0][0]',            \n                                                                  'embedding_5[0][0]']            \n                                                                                                  \n gru (GRU)                      (None, 128)          344832      ['concatenate[0][0]']            \n                                                                                                  \n dense (Dense)                  (None, 499121)       64386609    ['gru[0][0]']                    \n                                                                                                  \n==================================================================================================\nTotal params: 261,774,641\nTrainable params: 261,774,641\nNon-trainable params: 0\n__________________________________________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"ob.train(epoch = 2)","metadata":{"execution":{"iopub.status.busy":"2023-06-01T13:20:24.156326Z","iopub.execute_input":"2023-06-01T13:20:24.156786Z","iopub.status.idle":"2023-06-01T13:27:49.095436Z","shell.execute_reply.started":"2023-06-01T13:20:24.156742Z","shell.execute_reply":"2023-06-01T13:27:49.094271Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Epoch 1/2\n1517/1517 [==============================] - ETA: 0s - loss: 12.0407 - cosine_similarity: 367.2119\nEpoch 1: val_loss improved from inf to 11.12500, saving model to /kaggle/working/model_checkpoint.h5\n1517/1517 [==============================] - 286s 184ms/step - loss: 12.0407 - cosine_similarity: 367.2119 - val_loss: 11.1250 - val_cosine_similarity: 264.1793\nEpoch 2/2\n1517/1517 [==============================] - ETA: 0s - loss: 8.2602 - cosine_similarity: 57.6658\nEpoch 2: val_loss did not improve from 11.12500\n1517/1517 [==============================] - 104s 68ms/step - loss: 8.2602 - cosine_similarity: 57.6658 - val_loss: 11.1590 - val_cosine_similarity: 60.0115\n","output_type":"stream"}]},{"cell_type":"code","source":"y_pre = ob.test_2_testwithendone(n = 1000)","metadata":{"execution":{"iopub.status.busy":"2023-06-01T13:29:09.587612Z","iopub.execute_input":"2023-06-01T13:29:09.587964Z","iopub.status.idle":"2023-06-01T13:29:23.403853Z","shell.execute_reply.started":"2023-06-01T13:29:09.587937Z","shell.execute_reply":"2023-06-01T13:29:23.402712Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"2/2 [==============================] - 0s 9ms/step\n2/2 [==============================] - 0s 9ms/step\n2/2 [==============================] - 0s 9ms/step\n2/2 [==============================] - 0s 9ms/step\n2/2 [==============================] - 0s 9ms/step\n2/2 [==============================] - 0s 10ms/step\n2/2 [==============================] - 0s 10ms/step\n2/2 [==============================] - 0s 8ms/step\n2/2 [==============================] - 0s 9ms/step\n2/2 [==============================] - 0s 9ms/step\n2/2 [==============================] - 0s 9ms/step\n2/2 [==============================] - 0s 9ms/step\n2/2 [==============================] - 0s 9ms/step\n2/2 [==============================] - 0s 25ms/step\n2/2 [==============================] - 0s 9ms/step\n2/2 [==============================] - 0s 8ms/step\nMRR for test1: 0.4512223893554617\n","output_type":"stream"}]},{"cell_type":"code","source":"ob.test_1_testontest()","metadata":{"execution":{"iopub.status.busy":"2023-06-01T13:27:54.493778Z","iopub.execute_input":"2023-06-01T13:27:54.494162Z","iopub.status.idle":"2023-06-01T13:28:23.098565Z","shell.execute_reply.started":"2023-06-01T13:27:54.494129Z","shell.execute_reply":"2023-06-01T13:28:23.097467Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"2/2 [==============================] - 0s 9ms/step\n2/2 [==============================] - 0s 9ms/step\n2/2 [==============================] - 0s 9ms/step\n2/2 [==============================] - 0s 9ms/step\n2/2 [==============================] - 0s 9ms/step\n2/2 [==============================] - 0s 9ms/step\n2/2 [==============================] - 0s 10ms/step\n2/2 [==============================] - 0s 9ms/step\n2/2 [==============================] - 0s 10ms/step\n2/2 [==============================] - 0s 10ms/step\n2/2 [==============================] - 0s 9ms/step\n2/2 [==============================] - 0s 10ms/step\n2/2 [==============================] - 0s 10ms/step\n2/2 [==============================] - 0s 9ms/step\n2/2 [==============================] - 0s 9ms/step\n2/2 [==============================] - 0s 9ms/step\n2/2 [==============================] - 0s 9ms/step\n2/2 [==============================] - 0s 8ms/step\n2/2 [==============================] - 0s 9ms/step\n2/2 [==============================] - 0s 9ms/step\n2/2 [==============================] - 0s 9ms/step\n2/2 [==============================] - 0s 9ms/step\n2/2 [==============================] - 0s 10ms/step\n2/2 [==============================] - 0s 9ms/step\n2/2 [==============================] - 0s 10ms/step\n2/2 [==============================] - 0s 9ms/step\n2/2 [==============================] - 0s 8ms/step\n2/2 [==============================] - 0s 9ms/step\n2/2 [==============================] - 0s 9ms/step\n2/2 [==============================] - 0s 9ms/step\n2/2 [==============================] - 0s 10ms/step\n2/2 [==============================] - 0s 10ms/step\n2/2 [==============================] - 0s 10ms/step\n2/2 [==============================] - 0s 9ms/step\n2/2 [==============================] - 0s 10ms/step\n2/2 [==============================] - 0s 9ms/step\n2/2 [==============================] - 0s 9ms/step\n2/2 [==============================] - 0s 11ms/step\n2/2 [==============================] - 0s 13ms/step\n2/2 [==============================] - 0s 10ms/step\n2/2 [==============================] - 0s 9ms/step\n2/2 [==============================] - 0s 9ms/step\n2/2 [==============================] - 0s 9ms/step\n2/2 [==============================] - 0s 10ms/step\n1/1 [==============================] - 0s 28ms/step\nMRR for test1: 0.1703026447944764\n","output_type":"stream"}]},{"cell_type":"code","source":"y_pre = ob.test_3_generatefinalresult()\ny_pre","metadata":{"execution":{"iopub.status.busy":"2023-06-01T13:28:23.100087Z","iopub.execute_input":"2023-06-01T13:28:23.100569Z","iopub.status.idle":"2023-06-01T13:28:28.940183Z","shell.execute_reply.started":"2023-06-01T13:28:23.100530Z","shell.execute_reply":"2023-06-01T13:28:28.939061Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"2/2 [==============================] - 0s 9ms/step\n2/2 [==============================] - 0s 12ms/step\n","output_type":"stream"},{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"                                 next_item_prediction\n0   [B01HTOD43Y, B08F67XG18, B07BYCHMVY, B08HLJP1C...\n1   [B09GLLZFK2, B094R6BDN6, B09CLG5WKR, B0BFFSRNG...\n2   [B07KCKWGSG, B0865RL4PH, B095J18TP6, B00HZV9YE...\n3   [B01GN0M6NE, B09BCG9Z17, B08YK494ZZ, B09W4CYBT...\n4   [B007CVCVUM, B09XBF84Y7, B014WLL3UI, B07H7915Z...\n..                                                ...\n95  [B08TCH3HSR, B01KZC1EAW, B099N5CWRF, B09HGYSFG...\n96  [B07P57Z363, B08FHSBDNC, B08R5BKKM6, B004ISW5Y...\n97  [B08HN5YZS4, B07P57Z363, B0B881WK35, B07L4S22N...\n98  [B01BRDU22O, B07VM92YRB, B075JJ5615, B0B7BDN73...\n99  [B09CSH2PX7, B00QMSSFJC, B08GYGFFZW, B07PS12BR...\n\n[100 rows x 1 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>next_item_prediction</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[B01HTOD43Y, B08F67XG18, B07BYCHMVY, B08HLJP1C...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[B09GLLZFK2, B094R6BDN6, B09CLG5WKR, B0BFFSRNG...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[B07KCKWGSG, B0865RL4PH, B095J18TP6, B00HZV9YE...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[B01GN0M6NE, B09BCG9Z17, B08YK494ZZ, B09W4CYBT...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[B007CVCVUM, B09XBF84Y7, B014WLL3UI, B07H7915Z...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>95</th>\n      <td>[B08TCH3HSR, B01KZC1EAW, B099N5CWRF, B09HGYSFG...</td>\n    </tr>\n    <tr>\n      <th>96</th>\n      <td>[B07P57Z363, B08FHSBDNC, B08R5BKKM6, B004ISW5Y...</td>\n    </tr>\n    <tr>\n      <th>97</th>\n      <td>[B08HN5YZS4, B07P57Z363, B0B881WK35, B07L4S22N...</td>\n    </tr>\n    <tr>\n      <th>98</th>\n      <td>[B01BRDU22O, B07VM92YRB, B075JJ5615, B0B7BDN73...</td>\n    </tr>\n    <tr>\n      <th>99</th>\n      <td>[B09CSH2PX7, B00QMSSFJC, B08GYGFFZW, B07PS12BR...</td>\n    </tr>\n  </tbody>\n</table>\n<p>100 rows × 1 columns</p>\n</div>"},"metadata":{}}]}]}